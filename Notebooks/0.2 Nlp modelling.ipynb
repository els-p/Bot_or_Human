{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Bot or Human?: Binary Classification of Reddit Posts\n",
    "\n",
    "\n",
    "### Contents:\n",
    "- [Import Libraries](#Import-Libraries)\n",
    "- [Read in data scrapped from subreddits](#Read-in-data-scrapped-from-subreddits)\n",
    "- [Data Processing](#Data-Processing)\n",
    "- [NLP Modelling](#NLP-Modelling)\n",
    "- [Models Evaluation & Recommendation](#Models-Evaluation-&-Recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data scrapped from subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bot = pd.read_csv('../Data/bot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_human = pd.read_csv('../Data/human.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorises posts by indicting posts from Subredditsimulator as 1\n",
    "df_bot['bot'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>name</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is /r/SubredditSimulator?</td>\n",
       "      <td>t3_3g9ioz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only bots can post in /r/SubredditSimulator, c...</td>\n",
       "      <td>t3_3g9k92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cops tow golden Porsche for being 'rude' claim...</td>\n",
       "      <td>t3_cg1wva</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are you happy now that I’m currently pet sitting</td>\n",
       "      <td>t3_cfpfnu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harold's drinking problem hindered his love li...</td>\n",
       "      <td>t3_cg17b6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          post_title       name  bot\n",
       "0                     What is /r/SubredditSimulator?  t3_3g9ioz    1\n",
       "1  Only bots can post in /r/SubredditSimulator, c...  t3_3g9k92    1\n",
       "2  Cops tow golden Porsche for being 'rude' claim...  t3_cg1wva    1\n",
       "3   Are you happy now that I’m currently pet sitting  t3_cfpfnu    1\n",
       "4  Harold's drinking problem hindered his love li...  t3_cg17b6    1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorises posts by indicting posts from Showerthoughts as 0\n",
    "df_human['bot'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>name</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your Essential Guide to Showerthoughts</td>\n",
       "      <td>t3_bg71oh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Quintessential Showerthought, Issue #1 - O...</td>\n",
       "      <td>t3_bpql00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A clear toothpaste tube would make so much sense.</td>\n",
       "      <td>t3_cg37tn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When someone dies doing a dangerous hobby, it'...</td>\n",
       "      <td>t3_cg0v70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your bed has probably seen you go through more...</td>\n",
       "      <td>t3_cg4dqt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          post_title       name  bot\n",
       "0             Your Essential Guide to Showerthoughts  t3_bg71oh    0\n",
       "1  The Quintessential Showerthought, Issue #1 - O...  t3_bpql00    0\n",
       "2  A clear toothpaste tube would make so much sense.  t3_cg37tn    0\n",
       "3  When someone dies doing a dangerous hobby, it'...  t3_cg0v70    0\n",
       "4  Your bed has probably seen you go through more...  t3_cg4dqt    0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combines all data scrapped into one frame, first two pinned posts on rules are note included\n",
    "df = pd.concat([df_bot[2:], df_human[2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifies posts with empty title as NaN\n",
    "df = df.replace('',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_title    0\n",
       "name          0\n",
       "bot           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checks for NaN cells\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    857\n",
       "1    850\n",
       "Name: bot, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checks for representation of catogories\n",
    "df.bot.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Captures punctuation that specifically escapes string.punctuation\n",
    "#Converts to lowercase\n",
    "df['post_title'] = df['post_title'].str.lower().str.replace('’',':').str.replace('‘',':').str.replace('“',':')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes punctuation\n",
    "df['post_title_clean'] = df['post_title'].map(lambda x : ''.join(k for k in x if k not in string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>name</th>\n",
       "      <th>bot</th>\n",
       "      <th>post_title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cops tow golden porsche for being 'rude' claim...</td>\n",
       "      <td>t3_cg1wva</td>\n",
       "      <td>1</td>\n",
       "      <td>cops tow golden porsche for being rude claims ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>are you happy now that i:m currently pet sitting</td>\n",
       "      <td>t3_cfpfnu</td>\n",
       "      <td>1</td>\n",
       "      <td>are you happy now that im currently pet sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>harold's drinking problem hindered his love li...</td>\n",
       "      <td>t3_cg17b6</td>\n",
       "      <td>1</td>\n",
       "      <td>harolds drinking problem hindered his love lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i:ve read so many women embarassed about buyin...</td>\n",
       "      <td>t3_cg7qpo</td>\n",
       "      <td>1</td>\n",
       "      <td>ive read so many women embarassed about buying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what is with that one weird weight bar that do...</td>\n",
       "      <td>t3_cg6k1o</td>\n",
       "      <td>1</td>\n",
       "      <td>what is with that one weird weight bar that do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          post_title       name  bot  \\\n",
       "2  cops tow golden porsche for being 'rude' claim...  t3_cg1wva    1   \n",
       "3   are you happy now that i:m currently pet sitting  t3_cfpfnu    1   \n",
       "4  harold's drinking problem hindered his love li...  t3_cg17b6    1   \n",
       "5  i:ve read so many women embarassed about buyin...  t3_cg7qpo    1   \n",
       "6  what is with that one weird weight bar that do...  t3_cg6k1o    1   \n",
       "\n",
       "                                    post_title_clean  \n",
       "2  cops tow golden porsche for being rude claims ...  \n",
       "3    are you happy now that im currently pet sitting  \n",
       "4  harolds drinking problem hindered his love lif...  \n",
       "5  ive read so many women embarassed about buying...  \n",
       "6  what is with that one weird weight bar that do...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>name</th>\n",
       "      <th>bot</th>\n",
       "      <th>post_title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the people who manufacture dumpsters and greas...</td>\n",
       "      <td>t3_cg3gji</td>\n",
       "      <td>0</td>\n",
       "      <td>the people who manufacture dumpsters and greas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what specifically is illegal before i run out ...</td>\n",
       "      <td>t3_cclyb5</td>\n",
       "      <td>1</td>\n",
       "      <td>what specifically is illegal before i run out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>terrific folky cover of wake me up for june - ...</td>\n",
       "      <td>t3_caxbs1</td>\n",
       "      <td>1</td>\n",
       "      <td>terrific folky cover of wake me up for june   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[homemade] roes it look good for the new smoke...</td>\n",
       "      <td>t3_c09uej</td>\n",
       "      <td>1</td>\n",
       "      <td>homemade roes it look good for the new smoker ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shouting is much more effective in tv and movi...</td>\n",
       "      <td>t3_cg4xtj</td>\n",
       "      <td>0</td>\n",
       "      <td>shouting is much more effective in tv and movi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          post_title       name  bot  \\\n",
       "0  the people who manufacture dumpsters and greas...  t3_cg3gji    0   \n",
       "1  what specifically is illegal before i run out ...  t3_cclyb5    1   \n",
       "2  terrific folky cover of wake me up for june - ...  t3_caxbs1    1   \n",
       "3  [homemade] roes it look good for the new smoke...  t3_c09uej    1   \n",
       "4  shouting is much more effective in tv and movi...  t3_cg4xtj    0   \n",
       "\n",
       "                                    post_title_clean  \n",
       "0  the people who manufacture dumpsters and greas...  \n",
       "1  what specifically is illegal before i run out ...  \n",
       "2  terrific folky cover of wake me up for june   ...  \n",
       "3  homemade roes it look good for the new smoker ...  \n",
       "4  shouting is much more effective in tv and movi...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shuffles dataset before modelling\n",
    "df = shuffle(df)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Modelling\n",
    "Posts title chosen as features in design metrics. \n",
    "<br>Model target is the 'bot' column which indicates if post is from Subredditsimulator (is bot i.e. 1) or Showerthoughts (is not bot i.e. 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['post_title_clean']\n",
    "y = df['bot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The following classifiers are tested for the model with best score:\n",
    "    <br>\n",
    "<br>(1) Multinomial Naive Bayes (MNB) Classifier\n",
    "<br>(2) Bernoulli Naive Bayes (BNB) Classifier\n",
    "<br>(3) Logistic Regression (LR) Classifier</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer \n",
    "\n",
    "Converts texts from post titles to a matrix of token counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using MNB on count vectorised features</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=500, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(max_features=500, stop_words='english')),\n",
    "    ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6744730679156908"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec_nb_score = pipe.score(X_test,y_test)\n",
    "cvec_nb_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6795578878770729"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using BNB on count vectorised features</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=500, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('bn', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(max_features=500, stop_words='english')),\n",
    "    ('bn', BernoulliNB()),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6791569086651054"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec_bn_score = pipe.score(X_test,y_test)\n",
    "cvec_bn_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7065202105949135"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using LR on count vectorised features</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=500, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        s...enalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(max_features=500, stop_words='english')),\n",
    "    ('lr', LogisticRegression(solver='lbfgs')),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6791569086651054"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec_lr_score = pipe.score(X_test,y_test)\n",
    "cvec_lr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6877827511104251"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFidf Vectorizer\n",
    "Converts texts from post titles to a matrix of term frequency–inverse document frequency features. This numerical statistic reflects the importance a word to the collection of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using MNB on tf-idf vectorised features</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tvec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=500, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...True,\n",
       "        vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(max_features=500, stop_words='english')),\n",
    "    ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6510538641686182"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvec_nb_score = pipe.score(X_test,y_test)\n",
    "tvec_nb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6731217094544768"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using BNB on tf-idf vectorised features</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tvec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=500, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...  vocabulary=None)), ('bn', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(max_features=500, stop_words='english')),\n",
    "    ('bn', BernoulliNB()),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6791569086651054"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvec_bn_score = pipe.score(X_test,y_test)\n",
    "tvec_bn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7065202105949135"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using LR on tf-idf vectorised features</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tvec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=500, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...enalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(max_features=500, stop_words='english')),\n",
    "    ('lr', LogisticRegression(solver='lbfgs')),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6768149882903981"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvec_lr_score = pipe.score(X_test,y_test)\n",
    "tvec_lr_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.688943767042239"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash Vectorizer\n",
    "Converts texts from post titles to a matrix of token occurrences. Hash function is applied to features; hash values are used as indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using MNB on hash vectorised features</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('hvec', HashingVectorizer(alternate_sign=True, analyzer='word', binary=False,\n",
       "         decode_error='strict', dtype=<class 'numpy.float64'>,\n",
       "         encoding='utf-8', input='content', lowercase=True,\n",
       "         n_features=1048576, ngram_range=(1, 1), non_negative='total',\n",
       "         norm='l2', preprocessor=None, stop_words='english',\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('hvec', HashingVectorizer(stop_words='english', non_negative='total')),\n",
    "    ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvec_nb_score = pipe.score(X_test,y_test)\n",
    "hvec_nb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7328720138567337"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using BNB on hash vectorised features</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('hvec', HashingVectorizer(alternate_sign=True, analyzer='word', binary=False,\n",
       "         decode_error='strict', dtype=<class 'numpy.float64'>,\n",
       "         encoding='utf-8', input='content', lowercase=True,\n",
       "         n_features=1048576, ngram_range=(1, 1), non_negative='total',\n",
       "         norm='l2', ...   tokenizer=None)), ('bn', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('hvec', HashingVectorizer(stop_words='english', non_negative='total')),\n",
    "    ('bn', BernoulliNB()),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011709601873536"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvec_bn_score = pipe.score(X_test,y_test)\n",
    "hvec_bn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5020493560391693"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using LR on hash vectorised features</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('hvec', HashingVectorizer(alternate_sign=True, analyzer='word', binary=False,\n",
       "         decode_error='strict', dtype=<class 'numpy.float64'>,\n",
       "         encoding='utf-8', input='content', lowercase=True,\n",
       "         n_features=1048576, ngram_range=(1, 1), non_negative='total',\n",
       "         norm='l2', ...enalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('hvec', HashingVectorizer(stop_words='english', non_negative='total')),\n",
    "    ('lr', LogisticRegression(solver='lbfgs')),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.711943793911007"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvec_lr_score = pipe.score(X_test,y_test)\n",
    "hvec_lr_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7164857402548405"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Evaluation & Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVEC-MNB score:0.6744730679156908\n",
      "CVEC-BNB score:0.6791569086651054\n",
      "CVEC-LR score:0.6791569086651054\n",
      "\n",
      "\n",
      "TVEC-MNB score:0.6510538641686182\n",
      "TVEC-BNB score:0.6791569086651054\n",
      "TVEC-LR score:0.6768149882903981\n",
      "\n",
      "\n",
      "HVEC-MNB score:0.7142857142857143\n",
      "HVEC-BNB score:0.5011709601873536\n",
      "HVEC-LR score:0.711943793911007\n"
     ]
    }
   ],
   "source": [
    "print('CVEC-MNB score:{}'.format(cvec_nb_score))\n",
    "print('CVEC-BNB score:{}'.format(cvec_bn_score))\n",
    "print('CVEC-LR score:{}'.format(cvec_lr_score))\n",
    "print('\\n')\n",
    "print('TVEC-MNB score:{}'.format(tvec_nb_score))\n",
    "print('TVEC-BNB score:{}'.format(tvec_bn_score))\n",
    "print('TVEC-LR score:{}'.format(tvec_lr_score))\n",
    "print('\\n')\n",
    "print('HVEC-MNB score:{}'.format(hvec_nb_score))\n",
    "print('HVEC-BNB score:{}'.format(hvec_bn_score))\n",
    "print('HVEC-LR score:{}'.format(hvec_lr_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Comparing all the model scores, take the best performing model i.e. hash vectorised features fit to Logistic Regression Classifier, to check if introduction of penalty through Ridge/ Lasso Regression improves model performance. \n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using GridSearchCV to find best parameters for HVEC-LR model\n",
    "params_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': np.logspace(-4, 0, 40)\n",
    "}\n",
    "\n",
    "lr_gridsearch = GridSearchCV(\n",
    "    LogisticRegression(),\n",
    "    params_grid,\n",
    "    cv=5,\n",
    "    n_jobs=4,\n",
    "    verbose=1,\n",
    "    return_train_score=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvec = HashingVectorizer(stop_words='english', non_negative='total')\n",
    "X_train_hvec = hvec.fit_transform(X_train)\n",
    "X_test_hvec = hvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   56.7s finished\n"
     ]
    }
   ],
   "source": [
    "lr_gridsearch = lr_gridsearch.fit(X_train_hvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.711943793911007"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the best LR and its score on testing data\n",
    "best_lr = lr_gridsearch.best_estimator_\n",
    "best_lr.score(X_test_hvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.6235507341273913, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GridSearchCV throws out penalty through Lasso at alpha = 0.0587\n",
    "lr_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2685b278>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(lr_gridsearch.cv_results_)\n",
    "df = df[df['param_penalty'] == 'l2']\n",
    "df.plot(x='param_C', y='mean_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><b> In summary, best performing model to use is the Logistic Regression Classifier. Hash vectoriser should be used to preprocess data before passing into model for predictions. </b>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
