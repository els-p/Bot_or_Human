{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Bot or Human?: Exploring Data from Subreddits\n",
    "\n",
    "\n",
    "### Contents:\n",
    "- [Import Libraries](#Import-Libraries)\n",
    "- [Read in data scrapped from subreddits](#Read-in-data-scrapped-from-subreddits)\n",
    "- [Data Processing](#Data-Processing)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data scrapped from subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bot = pd.read_csv('../Data/bot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_human = pd.read_csv('../Data/human.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_posts(data):\n",
    "    '''\n",
    "    1. Captures punctuation that specifically escapes string.punctuation\n",
    "    2. Converts to lowercase\n",
    "    3. Removes punctuation\n",
    "    '''\n",
    "    data['post_title'] = data['post_title'].str.lower().str.replace('’',':').str.replace('‘',':').str.replace('“',':')\n",
    "    data['post_title_clean'] = data['post_title'].map(lambda x : ''.join(k for k in x if k not in string.punctuation))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [df_bot,df_human]:\n",
    "    clean_posts(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bot = df_bot['post_title_clean']\n",
    "X_human = df_human['post_title_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_words(corpus, num_words):\n",
    "    '''\n",
    "    1. Converts text data into matrix of token counts\n",
    "    2. Sums and sorts words in data, starting from highest count\n",
    "    3. Returns a number of words (num_words) which has the highest counts\n",
    "    '''\n",
    "    cvec = CountVectorizer(max_features=500, stop_words='english')\n",
    "    df = pd.DataFrame(cvec.fit_transform(corpus).todense(),columns=cvec.get_feature_names())\n",
    "    word_counts = df.sum(axis=0)\n",
    "    return word_counts.sort_values(ascending = False).head(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "like      44\n",
       "just      38\n",
       "im        33\n",
       "time      30\n",
       "dont      28\n",
       "man       27\n",
       "know      25\n",
       "people    24\n",
       "vs        24\n",
       "got       23\n",
       "years     21\n",
       "day       21\n",
       "did       20\n",
       "good      20\n",
       "need      19\n",
       "help      19\n",
       "new       18\n",
       "think     17\n",
       "friend    17\n",
       "mrw       15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words(X_bot, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "people      100\n",
       "probably     63\n",
       "just         58\n",
       "time         52\n",
       "like         38\n",
       "life         37\n",
       "way          36\n",
       "know         35\n",
       "dont         31\n",
       "years        29\n",
       "youre        29\n",
       "actually     27\n",
       "world        27\n",
       "make         26\n",
       "day          26\n",
       "water        23\n",
       "person       23\n",
       "say          20\n",
       "think        19\n",
       "humans       19\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words(X_human, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
